{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import library\n",
    "from converter import convert2doclevel\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download additional tagger module\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load original dataset, get span-level labels of each annotator, and convert them to document-level labels\n",
    "data_1 = convert2doclevel.convert2doclevel(r\"masked_dataset/dataset_original/masked_env_id_ann1.jsonl\")\n",
    "data_2 = convert2doclevel.convert2doclevel(r\"masked_dataset/dataset_original/masked_env_id_ann2.jsonl\")\n",
    "data_3 = convert2doclevel.convert2doclevel(r\"masked_dataset/dataset_original/masked_env_id_ann3.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load one of data from original dataset (annotator 1) to get 'text', 'id_shortcode', and 'topic' columns\n",
    "def read_jsonl(filename):\n",
    "  result = []\n",
    "  with open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "    for line in f.readlines():\n",
    "      result.append(json.loads(line))\n",
    "  return result\n",
    "ann1 = read_jsonl(r\"masked_dataset/dataset_original/masked_env_id_ann1.jsonl\")\n",
    "ann1 = pd.DataFrame(ann1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concat 'ann1' with document-level labels from each annotator (data_1, data_2, data_3)\n",
    "final_label = pd.concat([ann1[\"text\"], ann1['id_shortcode'], ann1['topic'], data_1[\"majority\"], data_2[\"majority\"], data_3[\"majority\"]],axis=1)\n",
    "final_label.columns = ['text', 'id_shortcode', 'topic', 'majority_1', 'majority_2', 'majority_3']\n",
    "\n",
    "## Create function to determine majority label from the three annotator labels on concatenated data\n",
    "def determine_majority(row):\n",
    "    labels = [row['majority_1'], row['majority_2'], row['majority_3']]\n",
    "    label_counts = {label: labels.count(label) for label in set(labels)}\n",
    "    max_count = max(label_counts.values())\n",
    "    majority_labels = [label for label, count in label_counts.items() if count == max_count]\n",
    "    \n",
    "    if len(majority_labels) == 1:\n",
    "        return majority_labels[0]\n",
    "    else:\n",
    "        return \"DELETED\"   \n",
    "final_label['final_label'] = final_label.apply(determine_majority, axis=1)\n",
    "\n",
    "## Save concatenated data to excel file\n",
    "final_label.to_excel(r\"masked_dataset/dataset_aggregated/masked_dataset_aggregated.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
